{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c225506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teddy.data.dataset import MsaLabels\n",
    "from teddy.lightning.datamodule import BDS_datamodule\n",
    "import teddy.data.Alphabet as alphabet\n",
    "from copy import deepcopy\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from torch import eye, ones\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.utils import BoxUniform\n",
    "\n",
    "\n",
    "alphabet_instance = alphabet.Alphabet(list( \"ATGCX-\"))\n",
    "\n",
    "train_ratio = 0.8\n",
    "batch_size = 16\n",
    "val_batch_size = 16\n",
    "\n",
    "msa = MsaLabels(dir = \"data/example/seq\", alphabet=alphabet_instance, limit_size=200)\n",
    "data = BDS_datamodule(data_dir = \"data/example/seq\", \n",
    "                      alphabet=alphabet_instance, \n",
    "                      train_ratio=train_ratio, \n",
    "                      val_batch_size=val_batch_size, \n",
    "                      batch_size=batch_size)\n",
    "\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e2e08",
   "metadata": {},
   "source": [
    "# Setting up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167eaf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/2174276119.py:21: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/2174276119.py:22: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  theta_batch = torch.Tensor(np.array(batch[1]))\n"
     ]
    }
   ],
   "source": [
    "from sbi.neural_nets.net_builders import build_nsf\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# Density estimator with first sequence and prior just for the dimensionality\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define training params\n",
    "learning_rate = 5e-4\n",
    "validation_fraction = 0.1  # 10% of the data will be used for validation\n",
    "stop_after_epochs = 20  # Stop training after 20 epochs with no improvement\n",
    "max_num_epochs = 2**31 - 1\n",
    "\n",
    "train_loader = data.train_dataloader()\n",
    "val_loader = data.val_dataloader()\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "\n",
    "x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
    "theta_batch = torch.Tensor(np.array(batch[1]))\n",
    "\n",
    "density_estimator = build_nsf(theta_batch, x_batch) # theta batch dimension, x batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3477989",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/4232536516.py:15: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/4232536516.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  theta_batch = torch.Tensor(np.array(batch[1]))\n",
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/4232536516.py:38: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/4232536516.py:39: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  theta_batch = torch.Tensor(np.array(batch[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 25 epochs\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = Adam(list(density_estimator.parameters()), lr=learning_rate)\n",
    "epoch, val_loss = 0, float(\"Inf\")\n",
    "\n",
    "best_val_loss = float(\"Inf\")\n",
    "\n",
    "converged = False\n",
    "\n",
    "while epoch <= max_num_epochs and not converged:\n",
    "    # Train for a single epoch.\n",
    "    density_estimator.train()\n",
    "    train_loss_sum = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
    "        theta_batch = torch.Tensor(np.array(batch[1]))\n",
    "\n",
    "        train_losses = density_estimator.loss(theta_batch, x_batch)\n",
    "        train_loss = torch.mean(train_losses)\n",
    "        train_loss_sum += train_losses.sum().item()\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    train_loss_average = train_loss_sum / (\n",
    "        len(train_loader) * train_loader.batch_size\n",
    "    )\n",
    "\n",
    "    # Calculate validation performance.\n",
    "    density_estimator.eval()\n",
    "    val_loss_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
    "            theta_batch = torch.Tensor(np.array(batch[1]))\n",
    "            val_losses = density_estimator.loss(\n",
    "                theta_batch,\n",
    "                x_batch,\n",
    "            )\n",
    "            val_loss_sum += val_losses.sum().item()\n",
    "\n",
    "    # Take mean over all validation samples.\n",
    "    val_loss = val_loss_sum / (len(val_loader) * val_loader.batch_size)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_since_last_improvement = 0\n",
    "        best_model_state_dict = deepcopy(density_estimator.state_dict())\n",
    "    else:\n",
    "        epochs_since_last_improvement += 1\n",
    "\n",
    "    # If no validation improvement over many epochs, stop training.\n",
    "    if epochs_since_last_improvement > stop_after_epochs - 1:\n",
    "        density_estimator.load_state_dict(best_model_state_dict)\n",
    "        converged = True\n",
    "        print(f'Neural network successfully converged after {epoch} epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bb0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/Documents/temp_folder/sbi-hackathon-2026/tmp_pip/ipykernel_20663/1140083748.py:4: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  x_o = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_o: torch.Size([16, 151702])            # Must have a batch dimension\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "\n",
    "x_o = torch.flatten(torch.Tensor(np.array(batch[0][0])), start_dim=1)\n",
    "\n",
    "print(f\"Shape of x_o: {x_o.shape}            # Must have a batch dimension\")\n",
    "\n",
    "samples = density_estimator.sample((1000,), condition=x_o).detach()\n",
    "print(\n",
    "    f\"Shape of samples: {samples.shape}  # Samples are returned with a batch dimension.\"\n",
    ")\n",
    "\n",
    "samples = samples.squeeze(dim=1)\n",
    "print(f\"Shape of samples: {samples.shape}     # Removed batch dimension.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
