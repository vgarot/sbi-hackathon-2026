{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d30650e",
   "metadata": {},
   "source": [
    "# Foundation Models for SBI: NPE-PFN\n",
    "\n",
    "**Time: ~15 minutes**\n",
    "\n",
    "In the previous notebooks, we:\n",
    "1. **Notebook 3**: Learned the `sbi` workflow for NPE (training normalizing flows)\n",
    "2. **Notebook 4**: Explored different summary statistics\n",
    "3. **Notebook 5**: Learned how to diagnose our posteriors\n",
    "\n",
    "In all these approaches, we had to **train** a neural network on our simulated data. What if we could skip training entirely?\n",
    "\n",
    "> **Foundation Models for SBI**: Pre-trained models that work \"out of the box\" on new problems!\n",
    "\n",
    "## What We'll Learn\n",
    "\n",
    "1. **NPE-PFN**: A foundation model for SBI based on Prior-data Fitted Networks (TabPFN)\n",
    "2. **Amortized inference without training**: Just provide (θ, x) pairs and get a posterior!\n",
    "3. **TSNPE-PFN**: Sequential version that focuses simulations on a specific observation\n",
    "\n",
    "**Paper**: [Simulation-Based Inference with the Prior-Data Fitted Networks](https://arxiv.org/abs/2407.20482)\n",
    "\n",
    "**Repository**: [github.com/mackelab/npe-pfn](https://github.com/mackelab/npe-pfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f8769",
   "metadata": {},
   "source": [
    "---\n",
    "## Installation\n",
    "\n",
    "The `npe-pfn` package needs to be cloned from GitHub. **Run the cell below once** to set it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing tabpfn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.8 environment at: /Users/danielgedon/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m51 packages\u001b[0m \u001b[2min 502ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m19 packages\u001b[0m \u001b[2min 421ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 153ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ tabpfn installed\n",
      "✓ Ready to import from npe_pfn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mInstalled \u001b[1m20 packages\u001b[0m \u001b[2min 101ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meval-type-backport\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==6.9.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.14.13\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabpfn\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabpfn-common-utils\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup npe-pfn (run once)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get absolute path (works in notebooks)\n",
    "npe_pfn_path = os.path.abspath(\"npe-pfn\")\n",
    "\n",
    "# Clone if needed\n",
    "if not os.path.exists(npe_pfn_path):\n",
    "    print(\"Cloning npe-pfn repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/mackelab/npe-pfn\", npe_pfn_path], check=True)\n",
    "\n",
    "# Add to Python path (so we can import without pip install)\n",
    "if npe_pfn_path not in sys.path:\n",
    "    sys.path.insert(0, npe_pfn_path)\n",
    "    print(f\"Added {npe_pfn_path} to sys.path\")\n",
    "\n",
    "# Install only tabpfn (the one missing dependency)\n",
    "try:\n",
    "    import tabpfn\n",
    "    print(\"✓ tabpfn already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing tabpfn...\")\n",
    "    subprocess.run([\"uv\", \"pip\", \"install\", \"tabpfn\"], check=True)\n",
    "    print(\"✓ tabpfn installed\")\n",
    "\n",
    "print(\"✓ Ready to import from npe_pfn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063e0e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_is_pandas_df' from 'sklearn.utils.validation' (/Users/danielgedon/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msbi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NPE\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msbi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pairplot\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnpe_pfn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabPFN_Based_NPE_PFN, run_tsnpe_pfn\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msimulators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     create_lotka_volterra_prior,\n\u001b[32m     12\u001b[39m     generate_observed_data,\n\u001b[32m     13\u001b[39m     lotka_volterra_simulator,\n\u001b[32m     14\u001b[39m     simulate,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/src/5_advanced/npe-pfn/npe_pfn/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnpe_pfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnpe_pfn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     TabPFN_Based_NPE_PFN,\n\u001b[32m      3\u001b[39m     TabPFN_Based_Uncond_Estimator,\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnpe_pfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtsnpe_pfn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_tsnpe_pfn\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTabPFN_Based_NPE_PFN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTabPFN_Based_Uncond_Estimator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_tsnpe_pfn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/src/5_advanced/npe-pfn/npe_pfn/npe_pfn.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabPFNClassifier, TabPFNRegressor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Distribution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/tabpfn/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabPFNClassifier\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdebug_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display_debug_info\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_loading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     load_fitted_tabpfn_model,\n\u001b[32m      7\u001b[39m     save_fitted_tabpfn_model,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn_common_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtelemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m track_model_call\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     ClassifierModelSpecs,\n\u001b[32m     38\u001b[39m     create_inference_engine,\n\u001b[32m     39\u001b[39m     determine_precision,\n\u001b[32m     40\u001b[39m     estimator_to_device,\n\u001b[32m     41\u001b[39m     get_embeddings,\n\u001b[32m     42\u001b[39m     initialize_model_variables_helper,\n\u001b[32m     43\u001b[39m     initialize_telemetry,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     46\u001b[39m     PROBABILITY_EPSILON_ROUND_ZERO,\n\u001b[32m     47\u001b[39m     SKLEARN_16_DECIMAL_PRECISION,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     YType,\n\u001b[32m     51\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEngine, InferenceEngineBatchedNoPreprocessing\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/tabpfn/base.py:43\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclean\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fix_dtypes\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     DevicesSpecification,\n\u001b[32m     38\u001b[39m     infer_devices,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     update_encoder_params,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ensure_compatible_predict_input_sklearn\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marchitectures\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbar_distribution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FullSupportBarDistribution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/tabpfn/validation.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabPFNValidationError\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_array, validate_data\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msettings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/tabpfn/misc/_sklearn_compat.py:263\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata_routing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    260\u001b[39m         _raise_for_params,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    261\u001b[39m         process_routing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    262\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    264\u001b[39m         _is_fitted,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    265\u001b[39m         _is_pandas_df,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    266\u001b[39m     )\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Upgrading for scikit-learn 1.5\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sklearn_version < parse_version(\u001b[33m\"\u001b[39m\u001b[33m1.5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# chunking\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# extmath\u001b[39;00m\n\u001b[32m    277\u001b[39m     \u001b[38;5;66;03m# fixes\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_is_pandas_df' from 'sklearn.utils.validation' (/Users/danielgedon/Dropbox/05_Postdoc/organizing/2601_hackathon_sbi_grenoble/sbi-hackathon-2026/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sbi.inference import NPE\n",
    "from sbi.analysis import pairplot\n",
    "\n",
    "from npe_pfn import TabPFN_Based_NPE_PFN, run_tsnpe_pfn\n",
    "\n",
    "from simulators import (\n",
    "    create_lotka_volterra_prior,\n",
    "    generate_observed_data,\n",
    "    lotka_volterra_simulator,\n",
    "    simulate,\n",
    ")\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Force CPU (NPE-PFN works on CPU)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c61ec",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Same Lotka-Volterra Problem\n",
    "\n",
    "We continue with the predator-prey model from previous notebooks. The goal is to infer the 4 Lotka-Volterra parameters from summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup prior and observed data\n",
    "prior = create_lotka_volterra_prior()\n",
    "x_o, theta_o = generate_observed_data(use_autocorrelation=True)\n",
    "\n",
    "# For visualization later\n",
    "time = np.arange(0, 200, 0.1)\n",
    "ts_observed = simulate(theta_o.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360f153",
   "metadata": {},
   "source": [
    "---\n",
    "## Think First!\n",
    "\n",
    "Before we use NPE-PFN, let's understand the key concepts:\n",
    "\n",
    "**Question 1**: Standard NPE requires training a neural network for each new problem. What are the advantages and disadvantages of this?\n",
    "\n",
    "**Question 2**: How can a pre-trained model work on problems it has never seen before?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answers</summary>\n",
    "\n",
    "1. **Standard NPE trade-offs:**\n",
    "   - **Advantages**: Tailored to your specific problem, can handle complex posteriors\n",
    "   - **Disadvantages**: Requires training time, need many simulations, hyperparameter tuning\n",
    "\n",
    "2. **How NPE-PFN generalizes:**\n",
    "   - Based on TabPFN, a transformer trained on synthetic tabular regression problems\n",
    "   - Learns \"how to do regression\" rather than a specific regression task\n",
    "   - At test time: Conditions on your (θ, x) pairs as context → outputs posterior!\n",
    "   - This is **in-context learning**: The model learns from examples you provide\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adcf77",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Standard NPE (Baseline)\n",
    "\n",
    "First, let's run standard NPE as a baseline for comparison. \n",
    "\n",
    "NOTE: we only consider 100 simulations here for now -- that is extremely little! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "num_simulations = 100\n",
    "\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = lotka_volterra_simulator(theta, use_autocorrelation=True)\n",
    "\n",
    "print(f\"Generated {num_simulations} simulations\")\n",
    "print(f\"theta shape: {theta.shape}, x shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train standard NPE\n",
    "print(\"Training standard NPE...\")\n",
    "npe = NPE(prior)\n",
    "npe.append_simulations(theta, x).train()\n",
    "\n",
    "posterior_npe = npe.build_posterior()\n",
    "samples_npe = posterior_npe.sample((10_000,), x=x_o)\n",
    "\n",
    "print(f\"\\nStandard NPE trained! Posterior samples shape: {samples_npe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beddabe",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: NPE-PFN (Foundation Model)\n",
    "\n",
    "Now let's use NPE-PFN — a foundation model that requires **no training**!\n",
    "\n",
    "### How NPE-PFN Works\n",
    "\n",
    "NPE-PFN is based on [TabPFN](https://arxiv.org/abs/2207.01848), a transformer that was pre-trained to solve tabular prediction problems. The key insight:\n",
    "\n",
    "1. **Pre-training**: TabPFN was trained on millions of synthetic regression problems\n",
    "2. **In-context learning**: At test time, it takes your (θ, x) pairs as \"context\"\n",
    "3. **Posterior prediction**: Given a new observation x_o, it predicts the posterior over θ\n",
    "\n",
    "**No gradient updates needed** — just forward passes through the pre-trained network!\n",
    "\n",
    "### The NPE-PFN Workflow\n",
    "\n",
    "```python\n",
    "# 1. Create the posterior object (loads pre-trained model)\n",
    "npe_pfn_posterior = TabPFN_Based_NPE_PFN(prior=prior)\n",
    "\n",
    "# 2. Append simulations (these become the \"context\" for in-context learning)\n",
    "npe_pfn_posterior.append_simulations(thetas, xs)\n",
    "\n",
    "# 3. Sample from posterior (no training step!)\n",
    "samples = npe_pfn_posterior.sample((num_samples,), x=x_o)\n",
    "```\n",
    "\n",
    "**Note**: The default context size is 10,000 simulations. If you provide more, NPE-PFN will filter them based on Euclidean distance to x_o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997339a6",
   "metadata": {},
   "source": [
    "### Your Task: Run NPE-PFN\n",
    "\n",
    "Complete the code below to run inference with NPE-PFN.\n",
    "\n",
    "**Hints**:\n",
    "- Create the posterior with `TabPFN_Based_NPE_PFN(prior=prior)`\n",
    "- Use `.append_simulations(theta, x)` to provide context (same data as standard NPE)\n",
    "- Sample with `.sample((num_samples,), x=x_o)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c53225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: NPE-PFN inference\n",
    "print(\"Running NPE-PFN (no training needed!)...\")\n",
    "\n",
    "# TODO for students: Create NPE-PFN posterior and append simulations\n",
    "# Hint: Use TabPFN_Based_NPE_PFN(prior=prior)\n",
    "\n",
    "npe_pfn_posterior = TabPFN_Based_NPE_PFN(prior=prior)\n",
    "npe_pfn_posterior.append_simulations(theta, x)\n",
    "\n",
    "# TODO for students: Sample from the posterior\n",
    "# Hint: No training needed! Just call .sample()\n",
    "\n",
    "samples_pfn = npe_pfn_posterior.sample((10_000,), x=x_o)\n",
    "\n",
    "print(f\"\\nNPE-PFN done! Posterior samples shape: {samples_pfn.shape}\")\n",
    "print(\"Notice: No training step was needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bdfb8d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: TSNPE-PFN (Sequential Version)\n",
    "\n",
    "Standard NPE-PFN uses simulations from the prior. But what if we want to focus on a specific observation?\n",
    "\n",
    "**TSNPE-PFN** (Truncated Sequential NPE-PFN) is a sequential variant that:\n",
    "1. Starts with prior samples\n",
    "2. Identifies which prior regions are consistent with x_o\n",
    "3. Focuses new simulations on promising regions\n",
    "4. Iterates to refine the posterior\n",
    "\n",
    "This is similar to SNPE (Sequential NPE) but using the foundation model!\n",
    "\n",
    "### The TSNPE-PFN Workflow\n",
    "\n",
    "```python\n",
    "# All-in-one function that handles the sequential rounds\n",
    "tsnpe_pfn_posterior, tsnpe_pfn_samples = run_tsnpe_pfn(\n",
    "    prior=prior,\n",
    "    simulator=simulator,\n",
    "    x_o=x_o,\n",
    "    num_simulations_per_round=500,  # Simulations per sequential round\n",
    "    num_rounds=3,                    # Number of sequential rounds\n",
    "    num_posterior_samples=10_000,    # Final posterior samples\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344b468",
   "metadata": {},
   "source": [
    "### Your Task: Run TSNPE-PFN\n",
    "\n",
    "Complete the code below to run sequential inference with TSNPE-PFN.\n",
    "\n",
    "**Hints**:\n",
    "- Use `run_tsnpe_pfn()` with the prior, simulator, and observation\n",
    "- The simulator should match the format we used: `lotka_volterra_simulator(theta, use_autocorrelation=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: TSNPE-PFN sequential inference\n",
    "print(\"Running TSNPE-PFN (sequential, focused on x_o)...\\n\")\n",
    "\n",
    "# Define simulator wrapper for TSNPE-PFN\n",
    "def simulator(theta):\n",
    "    return lotka_volterra_simulator(theta, use_autocorrelation=True)\n",
    "\n",
    "# TODO for students: Run TSNPE-PFN\n",
    "# Hint: Use run_tsnpe_pfn() with the prior, simulator, and observation\n",
    "\n",
    "tsnpe_pfn_posterior, samples_tsnpe = run_tsnpe_pfn(\n",
    "    prior=prior,\n",
    "    simulator=simulator,\n",
    "    x_o=x_o,\n",
    "    num_simulations_per_round=500,\n",
    "    num_rounds=3,\n",
    "    num_posterior_samples=10_000,\n",
    ")\n",
    "\n",
    "print(f\"\\nTSNPE-PFN done! Posterior samples shape: {samples_tsnpe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c01d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparing All Methods\n",
    "\n",
    "Now let's compare the posteriors from all three methods:\n",
    "1. **Standard NPE**: Trained normalizing flow\n",
    "2. **NPE-PFN**: Foundation model (no training)\n",
    "3. **TSNPE-PFN**: Sequential foundation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25512a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare posteriors with pairplot\n",
    "param_labels = [r\"$\\alpha$\", r\"$\\beta$\", r\"$\\delta$\", r\"$\\gamma$\"]\n",
    "limits = [[0.05, 0.15], [0.01, 0.03], [0.005, 0.03], [0.005, 0.15]]\n",
    "\n",
    "fig, axes = pairplot(\n",
    "    [samples_npe, samples_pfn, samples_tsnpe],\n",
    "    limits=limits,\n",
    "    labels=param_labels,\n",
    "    figsize=(10, 10),\n",
    "    points=theta_o,\n",
    "    points_colors=\"red\",\n",
    "    diag=\"kde\",\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "fig.legend(\n",
    "    [\"Standard NPE\", \"NPE-PFN\", \"TSNPE-PFN\"],\n",
    "    loc=\"upper right\",\n",
    "    bbox_to_anchor=(0.95, 0.95),\n",
    ")\n",
    "plt.suptitle(\"Posterior Comparison: Standard NPE vs Foundation Models\", y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b586819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare posterior statistics\n",
    "print(\"Parameter Recovery Comparison\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Parameter':<10} {'True':<10} {'NPE':<15} {'NPE-PFN':<15} {'TSNPE-PFN':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, (name, true_val) in enumerate(zip([\"α\", \"β\", \"δ\", \"γ\"], theta_o)):\n",
    "    npe_mean = samples_npe[:, i].mean().item()\n",
    "    npe_std = samples_npe[:, i].std().item()\n",
    "    pfn_mean = samples_pfn[:, i].mean().item()\n",
    "    pfn_std = samples_pfn[:, i].std().item()\n",
    "    tsnpe_mean = samples_tsnpe[:, i].mean().item()\n",
    "    tsnpe_std = samples_tsnpe[:, i].std().item()\n",
    "\n",
    "    print(f\"{name:<10} {true_val:.4f}    {npe_mean:.4f}±{npe_std:.3f}  {pfn_mean:.4f}±{pfn_std:.3f}  {tsnpe_mean:.4f}±{tsnpe_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Predictive Check for all methods\n",
    "def plot_posterior_predictive_comparison(samples_list, labels, theta_o, ts_observed, time, n_samples=30):\n",
    "    \"\"\"Compare posterior predictive simulations for multiple methods.\"\"\"\n",
    "    fig, axes = plt.subplots(len(samples_list), 2, figsize=(14, 4*len(samples_list)))\n",
    "\n",
    "    colors = [\"C0\", \"C1\", \"C2\"]\n",
    "\n",
    "    for row, (samples, label, color) in enumerate(zip(samples_list, labels, colors)):\n",
    "        indices = np.random.choice(len(samples), size=n_samples, replace=False)\n",
    "\n",
    "        for idx in indices:\n",
    "            theta_sample = samples[idx].numpy()\n",
    "            ts_sample = simulate(theta_sample)\n",
    "            axes[row, 0].plot(time, ts_sample[:, 0], color=color, alpha=0.2, linewidth=0.5)\n",
    "            axes[row, 1].plot(time, ts_sample[:, 1], color=color, alpha=0.2, linewidth=0.5)\n",
    "\n",
    "        # Plot ground truth\n",
    "        axes[row, 0].plot(time, ts_observed[:, 0], color=\"black\", linewidth=2, label=\"Observed\")\n",
    "        axes[row, 1].plot(time, ts_observed[:, 1], color=\"black\", linewidth=2, label=\"Observed\")\n",
    "\n",
    "        axes[row, 0].set_ylabel(\"Population\")\n",
    "        axes[row, 0].set_title(f\"Prey - {label}\")\n",
    "        axes[row, 0].legend()\n",
    "\n",
    "        axes[row, 1].set_title(f\"Predator - {label}\")\n",
    "        axes[row, 1].legend()\n",
    "\n",
    "    axes[-1, 0].set_xlabel(\"Time (days)\")\n",
    "    axes[-1, 1].set_xlabel(\"Time (days)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_posterior_predictive_comparison(\n",
    "    [samples_npe, samples_pfn, samples_tsnpe],\n",
    "    [\"Standard NPE\", \"NPE-PFN\", \"TSNPE-PFN\"],\n",
    "    theta_o, ts_observed, time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7b2e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Methods Comparison\n",
    "\n",
    "| Method | Training | Simulations | Best For |\n",
    "|--------|----------|-------------|----------|\n",
    "| **Standard NPE** | Required (minutes) | Many (1000+) | Production, complex posteriors |\n",
    "| **NPE-PFN** | None! | Moderate (100-10000) | Quick prototyping, iteration |\n",
    "| **TSNPE-PFN** | None! | Fewer (focused) | Single observation, refinement |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Foundation models skip training**: NPE-PFN gives posteriors instantly using in-context learning\n",
    "2. **Trade-offs exist**: Foundation models may be less flexible than trained models for complex problems\n",
    "3. **Sequential variants help**: TSNPE-PFN focuses simulations for better efficiency\n",
    "4. **Great for prototyping**: Try NPE-PFN first, then train a custom model if needed\n",
    "\n",
    "### The NPE-PFN Pattern\n",
    "\n",
    "```python\n",
    "from npe_pfn import TabPFN_Based_NPE_PFN, run_tsnpe_pfn\n",
    "\n",
    "# Amortized (works for any x_o)\n",
    "posterior = TabPFN_Based_NPE_PFN(prior=prior)\n",
    "posterior.append_simulations(thetas, xs)\n",
    "samples = posterior.sample((N,), x=x_o)\n",
    "\n",
    "# Sequential (focused on one x_o)\n",
    "posterior, samples = run_tsnpe_pfn(\n",
    "    prior=prior, simulator=simulator, x_o=x_o,\n",
    "    num_simulations_per_round=500, num_rounds=3\n",
    ")\n",
    "```\n",
    "\n",
    "**Further reading**: [NPE-PFN paper](https://arxiv.org/abs/2407.20482) | [GitHub repository](https://github.com/mackelab/npe-pfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cca3f",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Goals\n",
    "\n",
    "After this notebook, you should be able to:\n",
    "\n",
    "- ✅ Explain what foundation models are and why they're useful for SBI\n",
    "- ✅ Use NPE-PFN for instant posterior estimation without training\n",
    "- ✅ Apply TSNPE-PFN for sequential, observation-focused inference\n",
    "- ✅ Compare foundation models with standard NPE approaches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
