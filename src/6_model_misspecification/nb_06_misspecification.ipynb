{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Misspecification in SBI\n",
    "\n",
    "**Session 6** - Hands-on exercise (~35 min)\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. **Experience** misspecification: Train NPE on a simplified simulator, then evaluate on more realistic data\n",
    "2. **Detect** misspecification using methods from the `sbi` package\n",
    "3. **Understand** why detection matters and what to do when misspecification is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Problem: All Models Are Wrong\n",
    "\n",
    "Our Lotka-Volterra simulator makes simplifying assumptions. One key assumption:\n",
    "\n",
    "**Standard LV:** Predation rate is linear in prey density\n",
    "$$\\text{Prey eaten} = \\beta \\cdot x \\cdot y$$\n",
    "\n",
    "**Reality:** Predators have limited consumption capacity (they need time to handle/digest prey)\n",
    "$$\\text{Prey eaten} = \\frac{\\beta \\cdot x \\cdot y}{1 + h \\cdot x}$$\n",
    "\n",
    "This is called a **Type II functional response** (Holling, 1959). The parameter $h$ is the \"handling time\".\n",
    "\n",
    "When $h = 0$, we recover standard LV. When $h > 0$, predation saturates at high prey densities.\n",
    "\n",
    "**The scenario:**\n",
    "- We did not know about the Type II functional response and train NPE on our standard LV simulator ($h = 0$)\n",
    "- Then we apply our trained posterior estimator to real data to make predictions or draw conclusions\n",
    "- But the \"real\" observation comes from a system with predator saturation ($h > 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "from sbi.inference import NPE, simulate_for_sbi\n",
    "\n",
    "from simulators import (\n",
    "    create_lotka_volterra_prior,\n",
    "    lotka_volterra_simulator,\n",
    "    simulate,\n",
    ")\n",
    "from simulators.lotka_volterra import summarize_simulation, _get_stats\n",
    "from utils import corner_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup: Two Simulators\n",
    "\n",
    "We'll create two versions of the Lotka-Volterra simulator:\n",
    "1. **Training simulator**: Standard LV (what we assume)\n",
    "2. **Misspecified simulator**: LV with Type II functional response (closer to reality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USE_AUTOCORRELATION = True\n",
    "\n",
    "def lotka_volterra_ode(y: np.ndarray, alpha: float, beta: float, delta: float, gamma: float) -> np.ndarray:\n",
    "    \"\"\"Standard Lotka-Volterra differential equations (no predator saturation).\"\"\"\n",
    "    deer, wolves = y\n",
    "    ddeer_dt = alpha * deer - beta * deer * wolves\n",
    "    dwolves_dt = delta * deer * wolves - gamma * wolves\n",
    "    return np.asarray([ddeer_dt, dwolves_dt])\n",
    "\n",
    "def lotka_volterra_ode_typeII(y: np.ndarray, alpha: float, beta: float, delta: float, gamma: float, h: float) -> np.ndarray:\n",
    "    \"\"\"Lotka-Volterra with Type II functional response (predator saturation).\n",
    "    \n",
    "    The parameter h is the handling time. When h=0, this reduces to standard LV.\n",
    "    Larger h means more saturation (predators can't eat unlimited prey).\n",
    "    \"\"\"\n",
    "    deer, wolves = y\n",
    "    # Functional response: predation rate saturates at high prey density\n",
    "    functional_response = (beta * deer) / (1 + h * deer)\n",
    "    ddeer_dt = alpha * deer - functional_response * wolves\n",
    "    dwolves_dt = delta * functional_response * wolves / beta - gamma * wolves\n",
    "    return np.asarray([ddeer_dt, dwolves_dt])\n",
    "\n",
    "def simulate_typeII(parameters: np.ndarray, h: float = 0.02, time_span: float = 200.0) -> np.ndarray:\n",
    "    \"\"\"Simulate deer-wolf dynamics with Type II functional response.\n",
    "    \n",
    "    Uses same initial conditions and time step as the standard simulator for consistency.\n",
    "    \"\"\"\n",
    "    alpha, beta, delta, gamma = parameters\n",
    "    \n",
    "    initial_populations = np.asarray([40.0, 9.0])  # Same as standard simulator\n",
    "    dt = 0.1\n",
    "    \n",
    "    timesteps = int(time_span / dt)\n",
    "    populations = np.zeros((timesteps, 2))\n",
    "    populations[0] = initial_populations\n",
    "    \n",
    "    for i in range(1, timesteps):\n",
    "        populations[i] = (\n",
    "            populations[i - 1]\n",
    "            + lotka_volterra_ode_typeII(populations[i - 1], alpha, beta, delta, gamma, h) * dt\n",
    "        )\n",
    "    \n",
    "    return populations\n",
    "\n",
    "def misspecified_simulator(params: torch.Tensor, handling_time: float = 0.02) -> torch.Tensor:\n",
    "    \"\"\"LV simulator with Type II functional response (misspecified).\n",
    "    \n",
    "    Uses the same summary statistics pipeline as the standard simulator.\n",
    "    \"\"\"\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params_np = params.detach().cpu().numpy()\n",
    "    else:\n",
    "        params_np = np.array(params)\n",
    "    \n",
    "    if params_np.ndim == 1:\n",
    "        params_np = params_np.reshape(1, -1)\n",
    "    \n",
    "    batch_size = params_np.shape[0]\n",
    "    batch_summaries = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Simulate with Type II functional response\n",
    "        simulation_result = simulate_typeII(params_np[i], h=handling_time)\n",
    "        # Use same summary statistics as standard simulator\n",
    "        summary_stats = summarize_simulation(simulation_result, use_autocorrelation=USE_AUTOCORRELATION)\n",
    "        batch_summaries.append(summary_stats)\n",
    "    \n",
    "    return torch.tensor(np.array(batch_summaries), dtype=torch.float32)\n",
    "\n",
    "# Create standard simulator wrapper for consistency\n",
    "standard_simulator = partial(lotka_volterra_simulator, use_autocorrelation=USE_AUTOCORRELATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Difference\n",
    "\n",
    "Let's see how the Type II functional response changes the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters (same as used in other notebooks)\n",
    "theta_true = torch.tensor([0.1, 0.02, 0.01, 0.1])\n",
    "alpha, beta, delta, gamma = theta_true.numpy()\n",
    "\n",
    "# Time array\n",
    "time_span = 200.0\n",
    "dt = 0.1\n",
    "t = np.arange(0, time_span, dt)\n",
    "\n",
    "# Simulate both models using consistent initial conditions\n",
    "sol_standard = simulate(theta_true.numpy())  # Uses existing simulator\n",
    "sol_typeII = simulate_typeII(theta_true.numpy(), h=0.01)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Prey comparison\n",
    "ax = axes[0, 0]\n",
    "ax.plot(t, sol_standard[:, 0], 'b-', label='Standard LV', alpha=0.8)\n",
    "ax.plot(t, sol_typeII[:, 0], 'r--', label='Type II (misspecified)', alpha=0.8)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Prey Population')\n",
    "ax.set_title('Prey Dynamics')\n",
    "ax.legend()\n",
    "\n",
    "# Predator comparison\n",
    "ax = axes[0, 1]\n",
    "ax.plot(t, sol_standard[:, 1], 'b-', label='Standard LV', alpha=0.8)\n",
    "ax.plot(t, sol_typeII[:, 1], 'r--', label='Type II (misspecified)', alpha=0.8)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Predator Population')\n",
    "ax.set_title('Predator Dynamics')\n",
    "ax.legend()\n",
    "\n",
    "# Phase portrait\n",
    "ax = axes[1, 0]\n",
    "ax.plot(sol_standard[:, 0], sol_standard[:, 1], 'b-', label='Standard LV', alpha=0.8)\n",
    "ax.plot(sol_typeII[:, 0], sol_typeII[:, 1], 'r--', label='Type II', alpha=0.8)\n",
    "ax.set_xlabel('Prey')\n",
    "ax.set_ylabel('Predator')\n",
    "ax.set_title('Phase Portrait')\n",
    "ax.legend()\n",
    "\n",
    "# Summary statistics comparison (without noise, just to show the structural difference)\n",
    "ax = axes[1, 1]\n",
    "stats_standard = _get_stats(sol_standard[:, 0], use_autocorrelation=False)  # Prey only, no noise\n",
    "stats_typeII = _get_stats(sol_typeII[:, 0], use_autocorrelation=False)\n",
    "\n",
    "stat_names = ['Mean', 'Std', 'Max', 'Skew', 'Kurt']\n",
    "x_pos = np.arange(len(stat_names))\n",
    "width = 0.35\n",
    "\n",
    "# Normalize for visualization\n",
    "max_abs = np.maximum(np.abs(stats_standard).max(), np.abs(stats_typeII).max())\n",
    "prey_standard = stats_standard / max_abs\n",
    "prey_typeII = stats_typeII / max_abs\n",
    "\n",
    "ax.bar(x_pos - width/2, prey_standard, width, label='Standard LV', color='b', alpha=0.7)\n",
    "ax.bar(x_pos + width/2, prey_typeII, width, label='Type II', color='r', alpha=0.7)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(stat_names)\n",
    "ax.set_ylabel('Normalized Value')\n",
    "ax.set_title('Prey Summary Statistics (Normalized)')\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('Standard LV vs Type II Functional Response', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we observe?\n",
    "\n",
    "The Type II functional response causes:\n",
    "- **Lower peak amplitudes**: Predators can't exploit prey booms as effectively\n",
    "- **Different oscillation patterns**: The dynamics are subtly different\n",
    "- **Changed summary statistics**: Mean, std, max, and autocorrelation all differ\n",
    "\n",
    "This is exactly the kind of subtle mismatch that can cause problems for NPE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train NPE on Standard Simulator\n",
    "\n",
    "Now let's train NPE assuming our standard LV model is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUM_SIMULATIONS = 50000\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "# Create prior (same as other notebooks)\n",
    "prior = create_lotka_volterra_prior()\n",
    "\n",
    "print(f\"Prior bounds: {prior.base_dist.low.numpy()} to {prior.base_dist.high.numpy()}\")\n",
    "print(f\"True parameters: {theta_true.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data with STANDARD simulator (this is what we assume is correct)\n",
    "print(f\"Generating {NUM_SIMULATIONS} simulations with standard LV simulator...\")\n",
    "theta_train, x_train = simulate_for_sbi(standard_simulator, prior, NUM_SIMULATIONS, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Training data shapes: theta={theta_train.shape}, x={x_train.shape}\")\n",
    "print(f\"Summary statistics dimension: {x_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NPE\n",
    "print(\"Training NPE...\")\n",
    "trainer = NPE(prior)\n",
    "trainer.append_simulations(theta_train, x_train)\n",
    "trainer.train(training_batch_size=1000)\n",
    "\n",
    "posterior = trainer.build_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise 1: Experience Misspecification\n",
    "\n",
    "Now let's see what happens when we use NPE with a misspecified observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate observations\n",
    "x_o_wellspec = standard_simulator(theta_true)      # Well-specified (from training distribution)\n",
    "x_o_misspec = misspecified_simulator(theta_true)   # Misspecified (Type II functional response)\n",
    "\n",
    "print(f\"Well-specified observation shape: {x_o_wellspec.shape}\")\n",
    "print(f\"Misspecified observation shape: {x_o_misspec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from posterior for both observations\n",
    "print(\"Sampling from posterior...\")\n",
    "samples_wellspec = posterior.sample((5000,), x=x_o_wellspec)\n",
    "samples_misspec = posterior.sample((5000,), x=x_o_misspec)\n",
    "\n",
    "print(f\"\\nWell-specified observation:\")\n",
    "print(f\"  Posterior mean: {samples_wellspec.mean(dim=0).numpy()}\")\n",
    "print(f\"  Posterior std:  {samples_wellspec.std(dim=0).numpy()}\")\n",
    "print(f\"  True params:    {theta_true.numpy()}\")\n",
    "\n",
    "print(f\"\\nMisspecified observation:\")\n",
    "print(f\"  Posterior mean: {samples_misspec.mean(dim=0).numpy()}\")\n",
    "print(f\"  Posterior std:  {samples_misspec.std(dim=0).numpy()}\")\n",
    "print(f\"  True params:    {theta_true.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posteriors\n",
    "param_names = [r\"$\\alpha$\", r\"$\\beta$\", r\"$\\delta$\", r\"$\\gamma$\"]\n",
    "prior_limits = [[prior.base_dist.low[i].item(), prior.base_dist.high[i].item()] for i in range(4)]\n",
    "\n",
    "fig, axes = corner_plot(\n",
    "    [samples_wellspec, samples_misspec],\n",
    "    labels=[\"Well-specified\", \"Misspecified\"],\n",
    "    param_names=param_names,\n",
    "    theta_true=theta_true,\n",
    "    limits=prior_limits,\n",
    ")\n",
    "plt.suptitle('NPE Posteriors: Well-specified vs Misspecified Observation', y=1.02, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "**What do you observe?**\n",
    "- The posterior given the well-specified data covers the true parameters\n",
    "- The misspecified posterior is shifted and/or has different uncertainty\n",
    "\n",
    "**The problem:** With real data, we don't know $\\theta_{true}$, so we can't tell if the posterior is wrong!\n",
    "\n",
    "**This is why we need detection methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Predictive Check\n",
    "\n",
    "Let's also check if posterior samples produce data similar to the observation. This is a useful diagnostic even before formal detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate posterior predictive samples for both posteriors\n",
    "n_predictive = 50\n",
    "\n",
    "# Well-specified: sample parameters from posterior, simulate with standard simulator\n",
    "pred_theta_wellspec = samples_wellspec[:n_predictive]\n",
    "pred_x_wellspec = standard_simulator(pred_theta_wellspec)\n",
    "\n",
    "# Misspecified: sample parameters from posterior, simulate with standard simulator\n",
    "# Note: we use the standard simulator because that's what NPE was trained on\n",
    "pred_theta_misspec = samples_misspec[:n_predictive]\n",
    "pred_x_misspec = standard_simulator(pred_theta_misspec)\n",
    "\n",
    "# Generate time series for visualization\n",
    "ts_wellspec = [simulate(pred_theta_wellspec[i].numpy()) for i in range(n_predictive)]\n",
    "ts_misspec = [simulate(pred_theta_misspec[i].numpy()) for i in range(n_predictive)]\n",
    "\n",
    "# Ground truth time series\n",
    "ts_observed_wellspec = simulate(theta_true.numpy())\n",
    "ts_observed_misspec = simulate_typeII(theta_true.numpy(), h=0.02)  # What actually generated the misspecified observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posterior predictive: Time series comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Well-specified - Prey\n",
    "ax = axes[0, 0]\n",
    "for ts in ts_wellspec:\n",
    "    ax.plot(t, ts[:, 0], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(t, ts_observed_wellspec[:, 0], color=\"k\", linewidth=2, label=\"True (standard)\")\n",
    "ax.plot([], [], color=\"C0\", alpha=0.5, label=\"Predictive\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Well-specified: Prey (Deer)\")\n",
    "ax.legend()\n",
    "\n",
    "# Well-specified - Predator\n",
    "ax = axes[0, 1]\n",
    "for ts in ts_wellspec:\n",
    "    ax.plot(t, ts[:, 1], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(t, ts_observed_wellspec[:, 1], color=\"k\", linewidth=2, label=\"True (standard)\")\n",
    "ax.plot([], [], color=\"C0\", alpha=0.5, label=\"Predictive\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Well-specified: Predator (Wolf)\")\n",
    "ax.legend()\n",
    "\n",
    "# Misspecified - Prey\n",
    "ax = axes[1, 0]\n",
    "for ts in ts_misspec:\n",
    "    ax.plot(t, ts[:, 0], color=\"C1\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(t, ts_observed_misspec[:, 0], color=\"r\", linewidth=2, linestyle='--', label=\"True (Type II)\")\n",
    "ax.plot([], [], color=\"C1\", alpha=0.5, label=\"Predictive\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Misspecified: Prey (Deer)\")\n",
    "ax.legend()\n",
    "\n",
    "# Misspecified - Predator\n",
    "ax = axes[1, 1]\n",
    "for ts in ts_misspec:\n",
    "    ax.plot(t, ts[:, 1], color=\"C1\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(t, ts_observed_misspec[:, 1], color=\"r\", linewidth=2, linestyle='--', label=\"True (Type II)\")\n",
    "ax.plot([], [], color=\"C1\", alpha=0.5, label=\"Predictive\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Misspecified: Predator (Wolf)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle(\"Posterior Predictive Check: Do predictions match observations?\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey observation:\")\n",
    "print(\"  - Well-specified: Predictive samples should bracket the true trajectory\")\n",
    "print(\"  - Misspecified: Predictive samples may systematically miss the true trajectory\")\n",
    "print(\"    (because the true data came from Type II dynamics, not standard LV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detection Method 1: Prior Predictive Check\n",
    "\n",
    "The simplest check: do simulations from our model look like the observation?\n",
    "\n",
    "Generate many simulations from the prior and visually compare to $x_o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive check: compare x_o to prior predictive distribution\n",
    "n_prior_samples = 1000\n",
    "\n",
    "# We already have training data, let's use a subset\n",
    "x_prior_samples = x_train[:n_prior_samples]\n",
    "\n",
    "# Select a few summary statistics to visualize (moments only, first 5 for prey)\n",
    "stat_names = ['Mean', 'Std', 'Max', 'Skew', 'Kurt']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, name in enumerate(stat_names):\n",
    "    # Prey statistics (indices 0-4)\n",
    "    ax = axes[0, i]\n",
    "    ax.hist(x_prior_samples[:, i].numpy(), bins=30, alpha=0.7, density=True, label='Prior predictive')\n",
    "    ax.axvline(x_o_wellspec[0, i].item(), color='g', linewidth=2, linestyle='-', label='Well-spec')\n",
    "    ax.axvline(x_o_misspec[0, i].item(), color='r', linewidth=2, linestyle='--', label='Misspec')\n",
    "    ax.set_title(f'Prey {name}')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Density')\n",
    "    if i == 4:\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # Predator statistics (indices 10-14 with autocorr, or 5-9 without)\n",
    "    ax = axes[1, i]\n",
    "    pred_idx = i + 10  # With autocorrelation\n",
    "    ax.hist(x_prior_samples[:, pred_idx].numpy(), bins=30, alpha=0.7, density=True)\n",
    "    ax.axvline(x_o_wellspec[0, pred_idx].item(), color='g', linewidth=2, linestyle='-')\n",
    "    ax.axvline(x_o_misspec[0, pred_idx].item(), color='r', linewidth=2, linestyle='--')\n",
    "    ax.set_title(f'Predator {name}')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Density')\n",
    "\n",
    "plt.suptitle('Prior Predictive Check: Is $x_o$ compatible with the model?', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- **Well-specified observation (green)**: Should fall within the distribution of prior predictive samples\n",
    "- **Misspecified observation (red)**: May fall in the tails or outside the distribution for some statistics\n",
    "\n",
    "**Limitation:** This is visual and subjective. We need quantitative methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detection Method 2: Log-Probability Check\n",
    "\n",
    "**Idea:** Train a density estimator on simulated data $q(x) \\approx p(x)$, then check if $x_o$ has low probability.\n",
    "\n",
    "If $\\log q(x_o)$ is much lower than typical $\\log q(x)$ for simulated data, $x_o$ is likely out-of-distribution.\n",
    "\n",
    "The `sbi` package provides `MarginalTrainer` and `calc_misspecification_logprob()` for this.\n",
    "\n",
    "**Note:** Learning the full marginal distribution $p(x)$ can be challenging in high dimensions. For our 20D summary statistics, the marginal estimator may not learn the distribution perfectly, which can affect the reliability of this test. We show it here for completeness, but the MMD-based approach (next section) is often more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference.trainers.marginal import MarginalTrainer\n",
    "from sbi.diagnostics.misspecification import calc_misspecification_logprob\n",
    "\n",
    "# Train marginal density estimator q(x) on simulated data\n",
    "print(\"Training marginal density estimator...\")\n",
    "marginal_trainer = MarginalTrainer(density_estimator='NSF')  # Neural Spline Flow\n",
    "marginal_trainer.append_samples(x_train)  # unconditional, so only needs x.\n",
    "marginal_estimator = marginal_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation data to check the learned marginal estimator\n",
    "x_val = standard_simulator(prior.sample((1000,)))\n",
    "\n",
    "# Test well-specified observation\n",
    "p_value_wellspec, reject_wellspec = calc_misspecification_logprob(\n",
    "    x_val, x_o_wellspec, marginal_estimator\n",
    ")\n",
    "print(f\"Well-specified observation:\")\n",
    "print(f\"  p-value: {p_value_wellspec:.4f}\")\n",
    "print(f\"  Reject null (misspecification detected): {reject_wellspec}\")\n",
    "\n",
    "# Test misspecified observation\n",
    "p_value_misspec, reject_misspec = calc_misspecification_logprob(\n",
    "    x_val, x_o_misspec, marginal_estimator\n",
    ")\n",
    "print(f\"\\nMisspecified observation:\")\n",
    "print(f\"  p-value: {p_value_misspec:.4f}\")\n",
    "print(f\"  Reject null (misspecification detected): {reject_misspec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize log-probability distributions\n",
    "with torch.no_grad():\n",
    "    log_probs_val = marginal_estimator.log_prob(x_val).numpy()\n",
    "    log_prob_wellspec = marginal_estimator.log_prob(x_o_wellspec).item()\n",
    "    log_prob_misspec = marginal_estimator.log_prob(x_o_misspec).item()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(log_probs_val, bins=50, alpha=0.7, density=True, label='Validation data (from model)')\n",
    "ax.axvline(log_prob_wellspec, color='g', linewidth=2, linestyle='-', label=f'Well-spec (p={p_value_wellspec:.3f})')\n",
    "ax.axvline(log_prob_misspec, color='r', linewidth=2, linestyle='--', label=f'Misspec (p={p_value_misspec:.3f})')\n",
    "ax.set_xlabel('Log probability')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Log-Probability Based Misspecification Detection')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- **p-value ≈ 0.5**: Observation is typical of the model → no evidence of misspecification\n",
    "- **p-value < 0.05**: Observation is atypical → evidence of misspecification\n",
    "\n",
    "**Caveat:** Notice the warning above about c2st (classifier two-sample test). A c2st near 1.0 means the marginal estimator didn't learn the distribution well enough (a good estimator should have c2st ≈ 0.5). This is a common challenge: learning $p(x)$ unconditionally is often harder than learning $p(\\theta|x)$ conditionally. The results may still be informative, but should be interpreted with care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detection Method 3: MMD-Based Check with Embeddings\n",
    "\n",
    "**Idea:** Use an embedding network to map data into a latent space, then compute the Maximum Mean Discrepancy (MMD) between the observation and simulated data.\n",
    "\n",
    "MMD measures the distance between distributions in a kernel space. If $x_o$ is far from the simulated data distribution in embedding space, misspecification is likely.\n",
    "\n",
    "The `sbi` package provides `calc_misspecification_mmd()` for this. Because NPE learns an embedding network during training, we can reuse it directly!\n",
    "\n",
    "### Exercise: Use MMD-based detection\n",
    "\n",
    "Use `calc_misspecification_mmd` to test whether our observations are compatible with the model.\n",
    "\n",
    "```python\n",
    "from sbi.diagnostics.misspecification import calc_misspecification_mmd\n",
    "\n",
    "# API:\n",
    "p_value, (mmds_baseline, mmd_observed) = calc_misspecification_mmd(\n",
    "    inference=trainer,      # The trained NPE object\n",
    "    x_obs=x_o,              # The observation to test\n",
    "    x=x_val,                # Validation data from the simulator\n",
    "    mode=\"embedding\"        # Use the learned embedding space\n",
    ")\n",
    "```\n",
    "\n",
    "**Task:** Run the MMD check for both `x_o_wellspec` and `x_o_misspec`. What p-values do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.diagnostics.misspecification import calc_misspecification_mmd\n",
    "\n",
    "# Exercise: Run MMD check for both observations\n",
    "# Hint: You need validation data - use x_val from earlier (or generate new samples)\n",
    "\n",
    "# TODO: Test well-specified observation\n",
    "# p_value_mmd_wellspec, (mmds_baseline_wellspec, mmd_wellspec) = calc_misspecification_mmd(\n",
    "#     inference=...,\n",
    "#     x_obs=...,\n",
    "#     x=...,\n",
    "#     mode=\"embedding\"\n",
    "# )\n",
    "\n",
    "# TODO: Test misspecified observation\n",
    "# p_value_mmd_misspec, (mmds_baseline_misspec, mmd_misspec) = calc_misspecification_mmd(\n",
    "#     ...\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.diagnostics.misspecification import calc_misspecification_mmd\n",
    "\n",
    "# Test well-specified observation\n",
    "p_value_mmd_wellspec, (mmds_baseline_wellspec, mmd_wellspec) = calc_misspecification_mmd(\n",
    "    inference=trainer,\n",
    "    x_obs=x_o_wellspec,\n",
    "    x=x_val,\n",
    "    mode=\"embedding\"  # Use learned embedding space\n",
    ")\n",
    "print(f\"Well-specified observation (MMD):\")\n",
    "print(f\"  p-value: {p_value_mmd_wellspec:.4f}\")\n",
    "print(f\"  MMD: {mmd_wellspec:.6f}\")\n",
    "\n",
    "# Test misspecified observation\n",
    "p_value_mmd_misspec, (mmds_baseline_misspec, mmd_misspec) = calc_misspecification_mmd(\n",
    "    inference=trainer,\n",
    "    x_obs=x_o_misspec,\n",
    "    x=x_val,\n",
    "    mode=\"embedding\"\n",
    ")\n",
    "print(f\"\\nMisspecified observation (MMD):\")\n",
    "print(f\"  p-value: {p_value_mmd_misspec:.4f}\")\n",
    "print(f\"  MMD: {mmd_misspec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MMD distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.hist(mmds_baseline_wellspec, bins=30, alpha=0.7, density=True, label='Baseline MMD')\n",
    "ax.axvline(mmd_wellspec, color='g', linewidth=2, label=f'Observation (p={p_value_mmd_wellspec:.3f})')\n",
    "ax.set_xlabel('MMD')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Well-specified Observation')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.hist(mmds_baseline_misspec, bins=30, alpha=0.7, density=True, label='Baseline MMD')\n",
    "ax.axvline(mmd_misspec, color='r', linewidth=2, label=f'Observation (p={p_value_mmd_misspec:.3f})')\n",
    "ax.set_xlabel('MMD')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Misspecified Observation')\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('MMD-Based Misspecification Detection (Embedding Space)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary: Detection Results\n",
    "\n",
    "Let's summarize what we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MISSPECIFICATION DETECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Method':<25} {'Well-specified':<20} {'Misspecified':<20}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Log-prob p-value':<25} {p_value_wellspec:<20.4f} {p_value_misspec:<20.4f}\")\n",
    "print(f\"{'MMD p-value':<25} {p_value_mmd_wellspec:<20.4f} {p_value_mmd_misspec:<20.4f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"\\nInterpretation (α=0.05):\")\n",
    "print(f\"  Well-specified: {'No misspecification detected' if p_value_wellspec > 0.05 else 'Misspecification detected!'}\")\n",
    "print(f\"  Misspecified:   {'No misspecification detected' if p_value_misspec > 0.05 else 'Misspecification detected!'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Discussion: What To Do When Misspecification Is Detected?\n",
    "\n",
    "### Option 1: Fix the Simulator (Best if possible!)\n",
    "- Add the missing mechanism (e.g., Type II functional response)\n",
    "- Requires domain knowledge and may be complex\n",
    "\n",
    "### Option 2: Use Robust Inference Methods\n",
    "- **RNPE (Ward et al., 2022)**: Explicitly model the error between simulator and reality\n",
    "- **Robust embeddings (Huang & Bharti et al., 2023)**: Learn summary statistics that are insensitive to the mismatch\n",
    "- **RoPE/FRISBI (Wehenkel et al., 2024)**: Use optimal transport with calibration data\n",
    "\n",
    "### Option 3: Be Conservative\n",
    "- Report that misspecification was detected\n",
    "- Interpret posteriors with appropriate caveats\n",
    "- Consider broader uncertainty bounds\n",
    "\n",
    "### Key Takeaway\n",
    "**Always check for misspecification before trusting your posteriors!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Experienced misspecification**: Saw how NPE posteriors shift when the observation comes from a slightly different process\n",
    "\n",
    "2. **Learned three detection methods**:\n",
    "   - **Prior predictive check**: Visual comparison (subjective but interpretable)\n",
    "   - **Log-probability check**: Compare $\\log q(x_o)$ to validation distribution\n",
    "   - **MMD check**: Compare observation to simulations in embedding space\n",
    "\n",
    "3. **Key insight**: Detection methods give p-values; low p-values indicate the observation is incompatible with the model\n",
    "\n",
    "4. **Practical guidance**: \n",
    "   - Always run detection before trusting posteriors\n",
    "   - If misspecification is detected, consider fixing the simulator or using robust methods\n",
    "   - Report any detected misspecification honestly!\n",
    "\n",
    "---\n",
    "\n",
    "**Next steps for the hackathon:**\n",
    "- Think about what your simulator might be missing\n",
    "- Run these detection methods on your observations\n",
    "- If you detect misspecification, come talk to us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
