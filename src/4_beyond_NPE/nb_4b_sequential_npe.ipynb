{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Neural Posterior Estimation (SNPE)\n",
    "\n",
    "**Session 4, Part 3** - Hands-on exercise (~20 min)\n",
    "\n",
    "In the previous notebook, we saw that **NPE struggled** with the Lotka-Volterra problem while **NLE performed well**. The issue: NPE must learn accurate posteriors across the entire prior space, but the true posterior is sharply concentrated.\n",
    "\n",
    "**Solution: Sequential NPE (SNPE)** - Focus simulations where the posterior has mass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: The Problem with Amortized NPE\n",
    "\n",
    "With standard (amortized) NPE:\n",
    "\n",
    "```\n",
    "Sample θ from PRIOR → Simulate x → Train\n",
    "```\n",
    "\n",
    "**Problem:** Most prior samples produce observations far from $x_o$!\n",
    "- Wasted simulations in irrelevant regions\n",
    "- Poor posterior approximation where it matters\n",
    "- Need many simulations to cover the whole prior space\n",
    "\n",
    "### The Sequential Idea\n",
    "\n",
    "```\n",
    "Round 1: Sample θ from PRIOR      → Simulate → Train → Get rough posterior\n",
    "Round 2: Sample θ from POSTERIOR₁ → Simulate → Train → Get better posterior  \n",
    "Round 3: Sample θ from POSTERIOR₂ → Simulate → Train → Get refined posterior\n",
    "...\n",
    "```\n",
    "\n",
    "Each round **focuses simulations** on the region where the posterior has mass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The SNPE API in `sbi`\n",
    "\n",
    "The key pattern is a **loop** where each round:\n",
    "1. Samples from the current `proposal` (prior in round 1, posterior in later rounds)\n",
    "2. Simulates data for those parameters\n",
    "3. Trains the density estimator\n",
    "4. Builds a new posterior and sets it as the next proposal\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "**Initialization:**\n",
    "```python\n",
    "from sbi.inference import SNPE, simulate_for_sbi\n",
    "\n",
    "trainer = SNPE(prior)\n",
    "proposal = prior  # Start with prior\n",
    "```\n",
    "\n",
    "**Data generation** (works with any proposal - prior or posterior):\n",
    "```python\n",
    "theta, x = simulate_for_sbi(simulator, proposal, num_simulations, num_workers=NUM_WORKERS)\n",
    "```\n",
    "\n",
    "**Training** (must tell SNPE where samples came from):\n",
    "```python\n",
    "trainer.append_simulations(theta, x, proposal=proposal)  # proposal argument is crucial!\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "**Building posterior and updating proposal:**\n",
    "```python\n",
    "posterior = trainer.build_posterior()\n",
    "proposal = posterior.set_default_x(x_o)  # Makes posterior usable as next proposal\n",
    "```\n",
    "\n",
    "**Key insight:** `posterior.set_default_x(x_o)` conditions the posterior on your observation, so when `simulate_for_sbi` samples from it, you get θ values that are likely given $x_o$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "from sbi.inference import SNPE, simulate_for_sbi\n",
    "\n",
    "from simulators import (\n",
    "    create_lotka_volterra_prior,\n",
    "    generate_observed_data,\n",
    "    lotka_volterra_simulator,\n",
    ")\n",
    "from utils import corner_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUM_ROUNDS = 10\n",
    "NUM_SIMS_PER_ROUND = 2000\n",
    "NUM_WORKERS = 10  # Adjust based on your machine\n",
    "USE_AUTOCORRELATION = True\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Total simulations: {NUM_ROUNDS * NUM_SIMS_PER_ROUND}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup prior, simulator, and observation\n",
    "prior = create_lotka_volterra_prior()\n",
    "x_o, theta_true = generate_observed_data(use_autocorrelation=USE_AUTOCORRELATION)\n",
    "\n",
    "simulator = partial(lotka_volterra_simulator, use_autocorrelation=USE_AUTOCORRELATION)\n",
    "\n",
    "print(f\"True parameters: {theta_true.numpy()}\")\n",
    "print(f\"Observation shape: {x_o.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercise: Implement Multi-Round SNPE\n",
    "\n",
    "**Your task:** Complete the SNPE training loop below.\n",
    "\n",
    "For each round, you need to:\n",
    "1. Generate training data using `simulate_for_sbi` with the current `proposal`\n",
    "2. Append simulations to the trainer (don't forget the `proposal` argument!)\n",
    "3. Train the density estimator\n",
    "4. Build the posterior and store it\n",
    "5. **Crucially:** Update the `proposal` for the next round using `set_default_x(x_o)`\n",
    "\n",
    "**Hint:** Look at the API section above for the key function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "trainer = SNPE(prior)\n",
    "proposal = prior  # Start sampling from the prior\n",
    "posteriors = []   # Store posteriors from each round\n",
    "\n",
    "for round_idx in range(NUM_ROUNDS):\n",
    "    print(f\"\\n=== Round {round_idx + 1} ===\")\n",
    "    \n",
    "    # TODO Step 1: Generate training data by sampling from the proposal\n",
    "    # Use the built-in function simulate_for_sbi\n",
    "    print(f\"Simulating {NUM_SIMS_PER_ROUND} samples...\")\n",
    "    theta, x = simulate_for_sbi(???)\n",
    "    \n",
    "    # TODO Step 2: Append simulations to trainer\n",
    "    # Important: pass proposal=proposal so SNPE knows where samples came from\n",
    "    trainer.append_simulations(???)\n",
    "    \n",
    "    # TODO Step 3: Train\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    \n",
    "    # TODO Step 4: Build posterior and store it\n",
    "    posterior = ?\n",
    "    ...\n",
    "    \n",
    "    # TODO Step 5: Update proposal for next round\n",
    "    # Use posterior.set_default_x(x_o) to condition on our observation\n",
    "    proposal = ?\n",
    "\n",
    "print(\"\\n=== Done ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solutions_nb_4b_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample from Final Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples from each round for comparison\n",
    "num_posterior_samples = 1000\n",
    "samples_across_rounds = [posteriors[_].sample((num_posterior_samples,), x=x_o, show_progress_bars=False) for _ in range(len(posteriors))]\n",
    "snpe_samples = posteriors[-1].sample((num_posterior_samples,), x=x_o, show_progress_bars=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize: Posterior Evolution Across Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posterior evolution across rounds\n",
    "param_names = [r\"$\\alpha$\", r\"$\\beta$\", r\"$\\delta$\", r\"$\\gamma$\"]\n",
    "prior_limits = [[prior.base_dist.low[i].item(), prior.base_dist.high[i].item()] for i in range(4)]\n",
    "\n",
    "fig, axes = corner_plot(\n",
    "    samples_across_rounds,\n",
    "    labels=[f\"Round {i+1}\" for i in range(NUM_ROUNDS)],\n",
    "    param_names=param_names,\n",
    "    theta_true=theta_true,\n",
    "    # limits=prior_limits,\n",
    ")\n",
    "plt.suptitle(\"SNPE: Posterior Refinement Across Rounds\", y=1.02, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare: SNPE vs NPE vs NLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NPE and NLE samples from previous notebook\n",
    "import os\n",
    "\n",
    "if os.path.exists('npe_nle_samples.pt'):\n",
    "    saved_data = torch.load('npe_nle_samples.pt', weights_only=True)\n",
    "    npe_samples = saved_data['npe_samples']\n",
    "    nle_samples = saved_data['nle_samples']\n",
    "    print(\"Loaded NPE and NLE samples from nb_04\")\n",
    "else:\n",
    "    print(\"Warning: 'npe_nle_samples.pt' not found. Run nb_04 first!\")\n",
    "    print(\"Using placeholder values for comparison.\")\n",
    "    npe_samples = None\n",
    "    nle_samples = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison: SNPE vs NPE vs NLE posteriors\n",
    "if npe_samples is not None and nle_samples is not None:\n",
    "    fig, axes = corner_plot(\n",
    "        [npe_samples, nle_samples, snpe_samples],\n",
    "        labels=[\"NPE (20k)\", \"NLE (20k)\", \"SNPE (20k)\"],\n",
    "        param_names=param_names,\n",
    "        theta_true=theta_true,\n",
    "        # limits=prior_limits,\n",
    "    )\n",
    "    plt.suptitle(\"SNPE vs NPE vs NLE: Posterior Comparison\", y=1.02, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Posterior Predictive Check\n",
    "\n",
    "Let's validate SNPE by checking if simulations from posterior samples match the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulators import simulate\n",
    "\n",
    "# Generate predictive time series from SNPE posterior\n",
    "n_predictive = 50\n",
    "time = np.arange(0, 200, 0.1)\n",
    "\n",
    "# Observed time series\n",
    "ts_observed = simulate(theta_true.numpy())\n",
    "\n",
    "# SNPE predictive time series\n",
    "snpe_predictive_theta = snpe_samples[:n_predictive]\n",
    "ts_snpe = [simulate(snpe_predictive_theta[i].numpy()) for i in range(n_predictive)]\n",
    "\n",
    "# NPE and NLE predictive (if available)\n",
    "if npe_samples is not None:\n",
    "    npe_predictive_theta = npe_samples[:n_predictive]\n",
    "    ts_npe = [simulate(npe_predictive_theta[i].numpy()) for i in range(n_predictive)]\n",
    "if nle_samples is not None:\n",
    "    nle_predictive_theta = nle_samples[:n_predictive]\n",
    "    ts_nle = [simulate(nle_predictive_theta[i].numpy()) for i in range(n_predictive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictive time series: SNPE vs NPE vs NLE\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "\n",
    "# SNPE predictive\n",
    "ax = axes[0, 0]\n",
    "for ts in ts_snpe:\n",
    "    ax.plot(time, ts[:, 0], color=\"C2\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(time, ts_observed[:, 0], color=\"k\", linewidth=2, label=\"observed\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"SNPE (6k sims): Prey (Deer)\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[0, 1]\n",
    "for ts in ts_snpe:\n",
    "    ax.plot(time, ts[:, 1], color=\"C2\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(time, ts_observed[:, 1], color=\"k\", linewidth=2)\n",
    "ax.set_title(\"SNPE (6k sims): Predator (Wolf)\")\n",
    "\n",
    "# NPE predictive\n",
    "if npe_samples is not None:\n",
    "    ax = axes[1, 0]\n",
    "    for ts in ts_npe:\n",
    "        ax.plot(time, ts[:, 0], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "    ax.plot(time, ts_observed[:, 0], color=\"k\", linewidth=2, label=\"observed\")\n",
    "    ax.set_ylabel(\"Population\")\n",
    "    ax.set_title(\"NPE (20k sims): Prey (Deer)\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    for ts in ts_npe:\n",
    "        ax.plot(time, ts[:, 1], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "    ax.plot(time, ts_observed[:, 1], color=\"k\", linewidth=2)\n",
    "    ax.set_title(\"NPE (20k sims): Predator (Wolf)\")\n",
    "\n",
    "# NLE predictive\n",
    "if nle_samples is not None:\n",
    "    ax = axes[2, 0]\n",
    "    for ts in ts_nle:\n",
    "        ax.plot(time, ts[:, 0], color=\"C1\", alpha=0.2, linewidth=0.5)\n",
    "    ax.plot(time, ts_observed[:, 0], color=\"k\", linewidth=2, label=\"observed\")\n",
    "    ax.set_xlabel(\"Time (days)\")\n",
    "    ax.set_ylabel(\"Population\")\n",
    "    ax.set_title(\"NLE (20k sims): Prey (Deer)\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axes[2, 1]\n",
    "    for ts in ts_nle:\n",
    "        ax.plot(time, ts[:, 1], color=\"C1\", alpha=0.2, linewidth=0.5)\n",
    "    ax.plot(time, ts_observed[:, 1], color=\"k\", linewidth=2)\n",
    "    ax.set_xlabel(\"Time (days)\")\n",
    "    ax.set_title(\"NLE (20k sims): Predator (Wolf)\")\n",
    "\n",
    "plt.suptitle(\"Posterior Predictive Check: SNPE vs NPE vs NLE\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Discussion\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "| Method | Simulations | Posterior Quality | Amortized? |\n",
    "|--------|-------------|-------------------|------------|\n",
    "| NPE | 20,000 | Wider (struggled) | Yes |\n",
    "| NLE | 20,000 | Tight, accurate | Partial |\n",
    "| **SNPE** | **20,000** | Tight, accurate | No |\n",
    "\n",
    "### SNPE Trade-offs\n",
    "\n",
    "**Advantages:**\n",
    "- Much more simulation-efficient for a specific observation\n",
    "- Can achieve tight posteriors even when amortized NPE struggles\n",
    "- Iteratively improves the posterior estimate\n",
    "\n",
    "**Disadvantages:**\n",
    "- **Not amortized**: Must re-run for each new observation\n",
    "- Requires multiple training rounds (more wall-clock time)\n",
    "- Need to choose number of rounds and simulations per round\n",
    "\n",
    "### When to Use SNPE?\n",
    "\n",
    "1. **Expensive simulations**: Each simulation counts, can't afford 100k+ samples\n",
    "2. **Sharp posteriors**: Amortized NPE would need too many simulations\n",
    "3. **Single observation**: You have one $x_o$ and need the best possible posterior\n",
    "4. **Prior is broad**: Large prior-to-posterior contraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### The Sequential SBI Family\n",
    "\n",
    "| Method | What it learns | Sequential variant |\n",
    "|--------|---------------|-------------------|\n",
    "| NPE | $p(\\theta|x)$ | **SNPE** |\n",
    "| NLE | $p(x|\\theta)$ | SNLE |\n",
    "| NRE | $p(x|\\theta)/p(x)$ | SNRE |\n",
    "\n",
    "All sequential methods follow the same principle: **focus simulations where they matter**.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Sequential methods are simulation-efficient** - Important when simulations are expensive\n",
    "2. **Trade-off: efficiency vs amortization** - SNPE gives better posteriors but only for one $x_o$\n",
    "3. **SNPE can rescue NPE** - When amortized NPE struggles with sharp posteriors\n",
    "4. **Choose based on your use case**:\n",
    "   - Many observations, cheap simulations → NPE\n",
    "   - One observation, expensive simulations → SNPE\n",
    "   - Sharp posteriors, need MCMC flexibility → NLE/SNLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've now seen the main SBI methods:\n",
    "- ABC (Session 2)\n",
    "- NPE with neural density estimators (Sessions 2-3)\n",
    "- NLE with MCMC (Session 4)\n",
    "- SNPE for simulation efficiency (Session 4)\n",
    "\n",
    "You're (almost) ready for the **hackathon**! Apply these methods to your own problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SBI Hackathon)",
   "language": "python",
   "name": "sbi-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
