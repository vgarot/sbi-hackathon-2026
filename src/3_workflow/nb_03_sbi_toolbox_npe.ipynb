{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93030553",
   "metadata": {},
   "source": [
    "# NPE with the `sbi` Toolbox\n",
    "\n",
    "**Time: ~10 minutes**\n",
    "\n",
    "In the previous notebooks, we:\n",
    "1. **Notebook 1**: Implemented rejection ABC from scratch\n",
    "2. **Notebook 2**: Built a Neural Posterior Estimator (NPE) step-by-step in PyTorch\n",
    "\n",
    "Now let's see how easy it is to do **production-ready NPE** with the `sbi` package!\n",
    "\n",
    "The `sbi` package provides:\n",
    "- Flexible density estimators (normalizing flows, not just Gaussians!)\n",
    "- Automatic training with sensible defaults\n",
    "- Built-in diagnostics and validation tools\n",
    "- GPU support for faster training\n",
    "\n",
    "**Documentation**: [sbi.readthedocs.io](https://sbi.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sbi.inference import NPE\n",
    "from sbi.analysis import pairplot\n",
    "\n",
    "from simulators import (\n",
    "    create_lotka_volterra_prior,\n",
    "    generate_observed_data,\n",
    "    lotka_volterra_simulator,\n",
    "    simulate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d8b04",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Same Lotka-Volterra Problem\n",
    "\n",
    "We'll use the same predator-prey model from Notebook 1, but now with the `sbi` toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup prior and observed data (same as Notebook 1)\n",
    "prior = create_lotka_volterra_prior()\n",
    "x_o, theta_o = generate_observed_data(use_autocorrelation=True)\n",
    "\n",
    "print(f\"Prior: BoxUniform over 4 parameters (α, β, δ, γ)\")\n",
    "print(f\"Observed data shape: {x_o.shape} (20 summary statistics)\")\n",
    "print(f\"True parameters: α={theta_o[0]:.3f}, β={theta_o[1]:.3f}, δ={theta_o[2]:.3f}, γ={theta_o[3]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the observed time series (ground truth)\n",
    "# Note: x_o contains summary statistics, so we need simulate() to get the raw time series\n",
    "time = np.arange(0, 200, 0.1)\n",
    "ts_observed = simulate(theta_o.numpy())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(time, ts_observed[:, 0], color=\"k\", linewidth=2)\n",
    "ax.set_xlabel(\"Time (days)\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Observed Prey Dynamics\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(time, ts_observed[:, 1], color=\"k\", linewidth=2)\n",
    "ax.set_xlabel(\"Time (days)\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Observed Predator Dynamics\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"These time series are compressed into {x_o.shape[1]} summary statistics for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5de5d",
   "metadata": {},
   "source": [
    "---\n",
    "## Think First!\n",
    "\n",
    "Before we use `sbi`, let's review what NPE does:\n",
    "\n",
    "**Question 1**: What are the key steps in Neural Posterior Estimation?\n",
    "\n",
    "**Question 2**: Why is NPE called \"amortized\" inference?\n",
    "\n",
    "**Question 3**: What advantage does `sbi` offer over our hand-coded Gaussian NPE from Notebook 2?\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answers</summary>\n",
    "\n",
    "1. **NPE Steps**:\n",
    "   - Sample parameters from prior: θ ~ p(θ)\n",
    "   - Simulate data for each parameter: x ~ p(x|θ)\n",
    "   - Train a neural network to approximate the posterior: q(θ|x) ≈ p(θ|x)\n",
    "   - At inference: just run the network on the observation!\n",
    "\n",
    "2. **Amortized**: We pay the computational cost once (during training), then inference for any new observation is instant — just a forward pass through the network!\n",
    "\n",
    "3. **`sbi` advantages**: Uses **normalizing flows** instead of simple Gaussians, which can model complex, multi-modal posteriors with correlations. Also handles training, validation, and diagnostics automatically.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face0fb0",
   "metadata": {},
   "source": [
    "---\n",
    "## The `sbi` Workflow in 4 Steps\n",
    "\n",
    "The NPE workflow with `sbi` follows 4 core steps:\n",
    "\n",
    "1. **Generate training data** by sampling parameters from the prior and simulating corresponding data.\n",
    "2. **Train the neural network** on simulated parameter/data pairs to learn an approximation to the posterior.\n",
    "3. **Build the posterior estimator** from the trained network.\n",
    "4. **Sample from the learned posterior** given the observed data.\n",
    "\n",
    "For detailed code examples and advanced usage, see the [sbi documentation](https://sbi.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4191433",
   "metadata": {},
   "source": [
    "### Your Task: Implement the SBI Workflow\n",
    "\n",
    "Complete the code below to run NPE on the Lotka-Volterra model using `sbi`.\n",
    "\n",
    "**Hints**:\n",
    "- Use `prior.sample((n,))` to sample n parameters\n",
    "- Use `lotka_volterra_simulator(theta, use_autocorrelation=True)` to simulate\n",
    "- The `NPE` class takes the prior as its first argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate training data\n",
    "num_simulations = 10_000\n",
    "\n",
    "# TODO: Sample parameters from the prior\n",
    "theta = ...  # prior.sample(...)\n",
    "\n",
    "# TODO: Simulate summary statistics for each parameter set\n",
    "x = ...  # lotka_volterra_simulator(..., use_autocorrelation=True)\n",
    "\n",
    "print(f\"Generated {num_simulations} simulations\")\n",
    "print(f\"theta shape: {theta.shape}, x shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time series for a subset of prior samples\n",
    "n_visualize = 50\n",
    "ts_prior = [simulate(theta[i].numpy()) for i in range(n_visualize)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "for ts in ts_prior:\n",
    "    ax.plot(time, ts[:, 0], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(time, ts_observed[:, 0], color=\"k\", linewidth=2, label=r\"observed ($\\theta_o$)\")\n",
    "ax.plot([], [], color=\"C0\", alpha=0.5, label=\"prior samples\")\n",
    "ax.set_xlabel(\"Time (days)\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Prey Dynamics\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "for ts in ts_prior:\n",
    "    ax.plot(time, ts[:, 1], color=\"C0\", alpha=0.2, linewidth=0.5)\n",
    "ax.plot(time, ts_observed[:, 1], color=\"k\", linewidth=2, label=r\"observed ($\\theta_o$)\")\n",
    "ax.plot([], [], color=\"C0\", alpha=0.5, label=\"prior samples\")\n",
    "ax.set_xlabel(\"Time (days)\")\n",
    "ax.set_ylabel(\"Population\")\n",
    "ax.set_title(\"Predator Dynamics\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26012227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the neural network\n",
    "# TODO: Create NPE object and train it\n",
    "\n",
    "npe = ...  # NPE(...)\n",
    "# npe.append_simulations(...).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b574290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build posterior and sample\n",
    "# TODO: Build the posterior object\n",
    "\n",
    "posterior = ...  # npe.build_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ca256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Sample from posterior given the observation\n",
    "# TODO: Draw 10,000 samples from the posterior\n",
    "\n",
    "samples = ...  # posterior.sample(..., x=x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6fa69b",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualize the Results\n",
    "\n",
    "The `sbi` package includes a handy `pairplot` function for visualizing posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posterior with pairplot\n",
    "param_labels = [r\"$\\alpha$\", r\"$\\beta$\", r\"$\\delta$\", r\"$\\gamma$\"]\n",
    "\n",
    "fig, axes = pairplot(\n",
    "    samples,\n",
    "    limits=[[0.05, 0.15], [0.01, 0.03], [0.005, 0.03], [0.005, 0.15]],\n",
    "    labels=param_labels,\n",
    "    figsize=(8, 8),\n",
    "    points=theta_o,  # True parameters\n",
    "    points_colors=\"r\",\n",
    ")\n",
    "plt.suptitle(\"NPE Posterior (sbi)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6625b7",
   "metadata": {},
   "source": [
    "### Compare with Ground Truth\n",
    "\n",
    "Let's check how well the posterior captures the true parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04adf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare posterior statistics with true values\n",
    "print(\"Parameter Recovery:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (name, true_val) in enumerate(zip([\"α\", \"β\", \"δ\", \"γ\"], theta_o)):\n",
    "    mean = samples[:, i].mean().item()\n",
    "    std = samples[:, i].std().item()\n",
    "    print(f\"{name}: True = {true_val:.4f}, Posterior = {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a311a",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### The `sbi` Workflow\n",
    "\n",
    "| Step | Code | What it does |\n",
    "|------|------|--------------|\n",
    "| 1. Generate data | `theta = prior.sample((N,))` <br> `x = simulator(theta)` | Sample parameters, run simulations |\n",
    "| 2. Train | `NPE(prior).append_simulations(theta, x).train()` | Train normalizing flow on (θ, x) pairs |\n",
    "| 3. Build posterior | `npe.build_posterior()` | Create posterior object for sampling |\n",
    "| 4. Infer | `posterior.sample((M,), x=x_o)` | Draw samples given observation |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **`sbi` makes NPE easy**: The entire workflow fits in ~5 lines of code\n",
    "- **Flexible posteriors**: Uses normalizing flows, not just Gaussians\n",
    "- **Amortized**: Train once, infer instantly for any new observation\n",
    "- **Production-ready**: Includes diagnostics, validation, GPU support\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "The `sbi` package offers much more:\n",
    "- **Sequential methods** (SNPE): Focus simulations on regions of interest\n",
    "- **Other algorithms**: NLE (likelihood estimation), NRE (ratio estimation)\n",
    "- **Diagnostics**: Simulation-based calibration, coverage tests\n",
    "- **Advanced features**: Custom networks, embedding nets for high-dimensional data\n",
    "\n",
    "Explore the documentation: [sbi.readthedocs.io](https://sbi.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f1eb6",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Goals\n",
    "\n",
    "After this notebook, you should be able to:\n",
    "\n",
    "- Use the `sbi` package to run NPE on a simulator\n",
    "- Explain the 4-step `sbi` workflow\n",
    "- Visualize posteriors using `sbi.analysis.pairplot`\n",
    "- Appreciate how `sbi` simplifies production-ready SBI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
